{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1800 validated image filenames.\n",
      "Found 100 validated image filenames.\n",
      "Found 100 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"/workspace/data/miml_dataset/miml_labels_1.csv\")\n",
    "columns=[\"desert\", \"mountains\", \"sea\", \"sunset\", \"trees\"]\n",
    "datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=df[:1800],\n",
    "directory=\"/workspace/data/miml_dataset/images\",\n",
    "x_col=\"Filenames\",\n",
    "y_col=columns,\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"other\",\n",
    "target_size=(100,100))\n",
    "valid_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=df[1800:1900],\n",
    "directory=\"/workspace/data/miml_dataset/images\",\n",
    "x_col=\"Filenames\",\n",
    "y_col=columns,\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"other\",\n",
    "target_size=(100,100))\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=df[1900:],\n",
    "directory=\"/workspace/data/miml_dataset/images\",\n",
    "x_col=\"Filenames\",\n",
    "batch_size=1,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "target_size=(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/workspace/data/miml_dataset/miml_labels_2.csv\")\n",
    "df[\"labels\"]=df[\"labels\"].apply(lambda x:x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1800 validated image filenames belonging to 5 classes.\n",
      "Found 100 validated image filenames belonging to 5 classes.\n",
      "Found 100 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=df[:1800],\n",
    "directory=\"/workspace/data/miml_dataset/images\",\n",
    "x_col=\"Filenames\",\n",
    "y_col=\"labels\",\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "classes=[\"desert\", \"mountains\", \"sea\", \"sunset\", \"trees\"],\n",
    "target_size=(100,100))\n",
    "valid_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=df[1800:1900],\n",
    "directory=\"/workspace/data/miml_dataset/images\",\n",
    "x_col=\"Filenames\",\n",
    "y_col=\"labels\",\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "classes=[\"desert\", \"mountains\", \"sea\", \"sunset\", \"trees\"],\n",
    "target_size=(100,100))\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=df[1900:],\n",
    "directory=\"/workspace/data/miml_dataset/images\",\n",
    "x_col=\"Filenames\",\n",
    "batch_size=1,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "target_size=(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(100,100,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "56/56 [==============================] - 49s 874ms/step - loss: 0.5009 - acc: 0.7685 - val_loss: 0.5512 - val_acc: 0.7104\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 35s 624ms/step - loss: 0.4277 - acc: 0.8097 - val_loss: 0.5461 - val_acc: 0.7441\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 35s 618ms/step - loss: 0.3952 - acc: 0.8248 - val_loss: 0.4233 - val_acc: 0.8382\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 50s 893ms/step - loss: 0.3765 - acc: 0.8328 - val_loss: 0.3656 - val_acc: 0.8441\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 34s 614ms/step - loss: 0.3706 - acc: 0.8416 - val_loss: 0.3522 - val_acc: 0.8479\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 43s 772ms/step - loss: 0.3482 - acc: 0.8484 - val_loss: 0.2555 - val_acc: 0.8735\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 45s 801ms/step - loss: 0.3319 - acc: 0.8524 - val_loss: 0.1837 - val_acc: 0.9324\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 42s 750ms/step - loss: 0.3366 - acc: 0.8542 - val_loss: 0.3880 - val_acc: 0.8235\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 44s 790ms/step - loss: 0.3219 - acc: 0.8597 - val_loss: 0.2851 - val_acc: 0.8646\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 49s 883ms/step - loss: 0.3194 - acc: 0.8674 - val_loss: 0.2418 - val_acc: 0.8794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f69fa2c3978>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 3s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bool = (pred >0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pred_bool.astype(int)\n",
    "columns=[\"desert\", \"mountains\", \"sea\", \"sunset\", \"trees\"]\n",
    "#columns should be the same order of y_col\n",
    "results=pd.DataFrame(predictions, columns=columns)\n",
    "results[\"Filenames\"]=test_generator.filenames\n",
    "ordered_cols=[\"Filenames\"]+columns\n",
    "results=results[ordered_cols]#To get the same column order\n",
    "results.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "labels = train_generator.class_indices\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "for row in pred_bool:\n",
    "    l=[]\n",
    "    for index,cls in enumerate(row):\n",
    "        if cls:\n",
    "            l.append(labels[index])\n",
    "    predictions.append(\",\".join(l))\n",
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
