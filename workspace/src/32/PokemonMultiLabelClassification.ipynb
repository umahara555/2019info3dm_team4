{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PokemonMultiLabelClassification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucaISBi0hjr0",
        "colab_type": "code",
        "outputId": "8eaaca65-e418-43df-a734-c874a27a353e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlWJt55uhner",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import regularizers, optimizers\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential, model_from_json, model_from_yaml\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.callbacks import History, ModelCheckpoint, EarlyStopping\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLCJ7ja5ncCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type_dict = {\n",
        "    \"Normal\":0, \"Fire\":1, \"Water\":2, \"Electric\":3, \"Grass\":4, \"Ice\":5, \n",
        "    \"Fighting\":6, \"Poison\":7, \"Ground\":8, \"Flying\":9, \"Psychic\":10, \"Bug\":11, \n",
        "    \"Rock\":12, \"Ghost\":13, \"Dragon\":14, \"Dark\":15,\"Steel\":16, \"Fairy\":17\n",
        "}\n",
        "\n",
        "data_dir = 'drive/My Drive/ii_expt_3/workspace/data/'\n",
        "\n",
        "def _load_images():\n",
        "    images_path = data_dir + 'images2/*'\n",
        "    image_paths = glob.glob(images_path)\n",
        "    image_paths.sort()\n",
        "    images_length = len(image_paths)\n",
        "    raw_images = []\n",
        "    for image_path,i in zip(image_paths, range(images_length)):\n",
        "        img = Image.open(image_path)\n",
        "        raw_images.append(np.array(img))\n",
        "        print(f'\\rloading images ... {i}/{images_length}', end='')\n",
        "    print(f'\\rloading images ... {images_length}/{images_length} done')\n",
        "    raw_images = np.array(raw_images)\n",
        "    return raw_images\n",
        "\n",
        "\n",
        "def _load_types():\n",
        "    types_file_path = data_dir + 'Pokemon.csv'\n",
        "    \n",
        "    print(f'\\rloading types data ... ', end='')\n",
        "    types_df = pd.read_csv(types_file_path, sep=',')\n",
        "    types_df.drop_duplicates(subset='Number', inplace=True)\n",
        "    types_df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "    # Type2がない場合,Type1で補完する\n",
        "    df = types_df.copy(deep=True)\n",
        "    ind = df[df['Type2'].isnull()]['Type2'].index\n",
        "    df.iloc[ind, 3] = df.iloc[ind, 2]\n",
        "\n",
        "    df_1 = df[\"Type1\"][:801]\n",
        "    df_1 = df_1.map(type_dict)\n",
        "    type1 = df_1.values\n",
        "\n",
        "    df_2 = df[\"Type2\"][:801]\n",
        "    df_2 = df_2.map(type_dict)\n",
        "    type2 = df_2.values\n",
        "    \n",
        "    print(f'\\rloading types data ... done')\n",
        "    \n",
        "    return type1, type2\n",
        "\n",
        "\n",
        "def _data_augmentation(images, labels):\n",
        "    new_images = []\n",
        "    new_labels = []\n",
        "    images_length = len(images)\n",
        "    for image,label,i in zip(images,labels,range(images_length)):\n",
        "        progress = f'{int((i/images_length)*100)}/100%'\n",
        "        print(f'\\rrunning data augmentation ... {progress}', end='')\n",
        "        for x in [-16, 0, 16]:\n",
        "            for y in [-16, 0, 16]:\n",
        "                img = image\n",
        "\n",
        "                # ずらし\n",
        "                img = np.roll(img, x, axis=1)\n",
        "                img = np.roll(img, y, axis=0)\n",
        "\n",
        "                # ずらし後のはみ出し削除\n",
        "                if y > 0:\n",
        "                    img[:y] = 0\n",
        "                elif y < 0:\n",
        "                    img[y:] = 0\n",
        "                if x > 0:\n",
        "                    img[:, :x] = 0\n",
        "                elif x < 0:\n",
        "                    img[:, x:] = 0\n",
        "\n",
        "                new_images.append(img)\n",
        "                new_labels.append(label)\n",
        "    \n",
        "    print(f'\\rrunning data augmentation ... 100/100% done')\n",
        "    return np.array(new_images),np.array(new_labels)\n",
        "\n",
        "# def _data_augmentation(images, labels):\n",
        "#     new_images = []\n",
        "#     new_labels = []\n",
        "#     images_length = len(images)\n",
        "#     for image,label,i in zip(images,labels,range(images_length)):\n",
        "#         progress = f'{int((i/images_length)*100)}/100%'\n",
        "#         print(f'\\rrunning data augmentation ... {progress}', end='')\n",
        "#         for x_flip in [0,1]:\n",
        "#             for y_flip in [0,1]:\n",
        "#                 for rot in ['stay','cw','ccw']:\n",
        "#                     for x in [-16, 0, 16]:\n",
        "#                         for y in [-16, 0, 16]:\n",
        "#                             img = image\n",
        "                            \n",
        "#                             # 回転\n",
        "#                             if rot=='stay' :  # そのまま\n",
        "#                                 pass\n",
        "#                             elif rot=='cw':  # 時計回りに90度\n",
        "#                                 img = np.rot90(img, k=1, axes=(0,1))\n",
        "#                             elif rot=='ccw':  # 反時計回りに90度\n",
        "#                                 img = np.rot90(img, k=1, axes=(1,0))\n",
        "                            \n",
        "#                             # 反転\n",
        "#                             img = np.flip(img, axis=1) if x_flip else img\n",
        "#                             img = np.flip(img, axis=0) if y_flip else img\n",
        "                            \n",
        "#                             # ずらし\n",
        "#                             img = np.roll(img, x, axis=1)\n",
        "#                             img = np.roll(img, y, axis=0)\n",
        "                            \n",
        "#                             # ずらし後のはみ出し削除\n",
        "#                             if y > 0:\n",
        "#                                 img[:y] = 0\n",
        "#                             elif y < 0:\n",
        "#                                 img[y:] = 0\n",
        "#                             if x > 0:\n",
        "#                                 img[:, :x] = 0\n",
        "#                             elif x < 0:\n",
        "#                                 img[:, x:] = 0\n",
        "                            \n",
        "#                             new_images.append(img)\n",
        "#                             new_labels.append(label)\n",
        "    \n",
        "#     print(f'\\rrunning data augmentation ... {100}/{100} done')\n",
        "#     return np.array(new_images),np.array(new_labels)\n",
        "\n",
        "def data_shuffle(images,types):\n",
        "    indices = np.arange(images.shape[0])\n",
        "    x,y = [], []\n",
        "    for i in indices:\n",
        "        x.append(images[i])\n",
        "        y.append(types[i])\n",
        "        \n",
        "    return np.array(x),np.array(y)\n",
        "\n",
        "\n",
        "def generate_model(img_rows,img_cols,img_channels,nb_classes):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (5, 5), \n",
        "                     padding='same', \n",
        "                     activation='relu', \n",
        "                     kernel_regularizer=regularizers.l2(0.001),\n",
        "                     input_shape=(img_rows,img_cols,img_channels)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Conv2D(64, (5, 5), \n",
        "                     padding='same', \n",
        "                     activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(0.001)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, \n",
        "                    activation='relu', \n",
        "                    kernel_regularizer=regularizers.l2(0.001)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(nb_classes, \n",
        "                    kernel_regularizer=regularizers.l2(0.001), \n",
        "                    activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizers.adam(lr=0.0001), \n",
        "                  loss='binary_crossentropy', \n",
        "                  metrics=[\"accuracy\"])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def generator(x, y, batch_size=32):\n",
        "    indices = np.arange(x.shape[0])\n",
        "    while True:\n",
        "        img_cahce, label_cache = [], []\n",
        "        np.random.shuffle(indices)\n",
        "        for i in indices:\n",
        "            img_cahce.append(x[i])\n",
        "            label_cache.append(y[i])\n",
        "            if len(img_cahce) == batch_size:\n",
        "                X_batch = np.array(img_cahce)\n",
        "                Y_batch = np.array(label_cache)\n",
        "                img_cahce, label_cache = [], []\n",
        "                yield X_batch, Y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwtf6fpCKJmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(raw_images, type1, type2):\n",
        "    # 画像の形状情報\n",
        "    img_rows = 64\n",
        "    img_cols = 64\n",
        "    img_channels = 3\n",
        "    nb_classes = 18\n",
        "    \n",
        "    # fit parameter\n",
        "    batch_size = 32\n",
        "    epochs = 2\n",
        "\n",
        "    # 前処理\n",
        "    images = raw_images.astype('float32') / 255.0\n",
        "    type1_c = np_utils.to_categorical(type1, nb_classes)\n",
        "    type2_c = np_utils.to_categorical(type2, nb_classes)\n",
        "    types = type1_c + type2_c\n",
        "    types = np.where(types > 1., 1., types)\n",
        "\n",
        "    imgs, ts = data_shuffle(images[:750], types[:750])\n",
        "#     img_train, type_train = _data_augmentation(imgs[:650], types[:650])\n",
        "#     img_valid, type_valid = _data_augmentation(imgs[650:750], types[650:750])\n",
        "    img_train, type_train = imgs[:650], types[:650]\n",
        "    img_valid, type_valid = imgs[650:750], types[650:750]\n",
        "#     img_test = images[750:]\n",
        "#     type_test = types[750:]\n",
        "\n",
        "    # TODO : class weight 算出処理\n",
        "    # w_data = pd.concat([types_df['Type1'][:750],types_df['Type2'][:750]]).value_counts(normalize=True,sort=True)\n",
        "    # class_weight = pd.Series(w_data.values[0] / w_data.values, index=w_data.index.map(type_dict)).to_dict()\n",
        "\n",
        "    model = generate_model(img_rows, img_cols, img_channels, nb_classes)\n",
        "    \n",
        "    # JSON形式でモデルを保存\n",
        "    json_string = model.to_json()\n",
        "    open('./pokemon_cnn.json', 'w').write(json_string)\n",
        "    #　初期ウエイトの保存\n",
        "    model.save_weights('./pokemon_cnn_init_weight.hdf5', overwrite=True)\n",
        "    \n",
        "    # バリデーションロスが下がれば、エポックごとにモデルを保存\n",
        "    cp_cb = ModelCheckpoint(filepath='./pokemon_cnn_best_weight1.hdf5', \n",
        "                            monitor='val_loss', \n",
        "                            verbose=1, \n",
        "                            save_best_only=True, \n",
        "                            mode='auto')\n",
        "\n",
        "    # バリデーションロスが５エポック連続で上がったら、ランを打ち切る\n",
        "    es_cb = EarlyStopping(monitor='val_loss', \n",
        "                          patience=5, \n",
        "                          verbose=0, \n",
        "                          mode='auto')\n",
        "    \n",
        "    history = History()\n",
        "\n",
        "    model.fit_generator(generator=generator(x=img_train, \n",
        "                                            y=type_train, \n",
        "                                            batch_size=batch_size),\n",
        "                        steps_per_epoch=len(img_train)//batch_size,\n",
        "                        validation_data=generator(x=img_valid, \n",
        "                                                  y=type_valid, \n",
        "                                                  batch_size=batch_size),\n",
        "                        validation_steps=len(img_valid)//batch_size, \n",
        "#                         class_weight=class_weight,\n",
        "                        verbose=1, \n",
        "                        epochs=epochs,\n",
        "                        callbacks=[history,cp_cb,es_cb])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Isl1Q13z4bk",
        "colab_type": "code",
        "outputId": "0b045283-a8da-4211-d42c-90b22e8c488c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "# mode : fit\n",
        "\n",
        "# Load data.\n",
        "raw_images = _load_images()\n",
        "type1, type2 = _load_types()\n",
        "\n",
        "# Run fit.\n",
        "fit(raw_images, type1, type2)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading images ... 801/801 done\n",
            "loading types data ... done\n",
            "Epoch 1/2\n",
            "20/20 [==============================] - 14s 710ms/step - loss: 1.4163 - acc: 0.8753 - val_loss: 1.2803 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.28033, saving model to ./pokemon_cnn_best_weight1.hdf5\n",
            "Epoch 2/2\n",
            "20/20 [==============================] - 11s 565ms/step - loss: 1.2160 - acc: 0.9161 - val_loss: 1.2241 - val_acc: 0.9144\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.28033 to 1.22407, saving model to ./pokemon_cnn_best_weight1.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iCLL9pGvVCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(image):\n",
        "    # 画像の形状情報\n",
        "    img_rows = 64\n",
        "    img_cols = 64\n",
        "    img_channels = 3\n",
        "    nb_classes = 18\n",
        "    \n",
        "    # 学習済みモデルとパラメータの呼び出し\n",
        "    json_string = open('./pokemon_cnn.json', 'r').read()\n",
        "    model = model_from_json(json_string)\n",
        "    model.load_weights('./pokemon_cnn_best_weight1.hdf5')\n",
        "\n",
        "    img =  np.array([image]).astype('float32') / 255.0\n",
        "\n",
        "    type_labels = {v: k for k, v in type_dict.items()} \n",
        "\n",
        "    # 予測\n",
        "    pred=model.predict(img, batch_size=1)\n",
        "\n",
        "    print(type_labels[np.argmax(pred[0])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NODvN8ptHW_k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3e1c7e33-9833-44b3-814f-c54c71f34c47"
      },
      "source": [
        "# mode : predict\n",
        "image = raw_images[751]\n",
        "predict(image)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Water\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdvxHhhyAsvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fig, ax = plt.subplots(12, 9, figsize=(18, 10))\n",
        "# for for_1 in range(12):\n",
        "#     for for_2 in range(9):\n",
        "#         ax[for_1][for_2].imshow(img[for_1*9+for_2].reshape(64, 64, 3))\n",
        "#         ax[for_1][for_2].axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs0fWkODbryF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}