{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras=2.2.4\n",
      "tensorflow=1.13.1\n",
      "dask=1.1.4\n"
     ]
    }
   ],
   "source": [
    "## development environment\n",
    "# keras=2.2.0\n",
    "# tensorflow=1.8.0\n",
    "# dask=0.18.1\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import dask\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"keras={}\".format(keras.__version__))\n",
    "print(\"tensorflow={}\".format(tf.__version__))\n",
    "print(\"dask={}\".format(dask.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可視化用ライブラリの読み込み\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Keras関連\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.layers import Dropout,Flatten,Conv2D,MaxPooling2D,BatchNormalization,Activation\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD, Adadelta, Adam, RMSprop# 最適化手法\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのインポート\n",
    "import dataset\n",
    "\n",
    "X, Y = dataset.load_data()\n",
    "\n",
    "# type1のみ使用\n",
    "y=Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train=X[0:700]\n",
    "# x_test=X[700:]\n",
    "\n",
    "# y_train=y[0:700]\n",
    "# y_test=y[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベル名を用意\n",
    "type_labels = np.array([\n",
    "    \"Normal\",\n",
    "    \"Fire\",\n",
    "    \"Water\",\n",
    "    \"Electric\",\n",
    "    \"Grass\",\n",
    "    \"Ice\",\n",
    "    \"Fighting\",\n",
    "    \"Poison\",\n",
    "    \"Ground\",\n",
    "    \"Flying\",\n",
    "    \"Psychic\",\n",
    "    \"Bug\",\n",
    "    \"Rock\",\n",
    "    \"Ghost\",\n",
    "    \"Dragon\",\n",
    "    \"Dark\",\n",
    "    \"Steel\",\n",
    "    \"Fairy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 64, 64\n",
    "img_channels = 4\n",
    "nb_classes = 18 # 正解のパターン数\n",
    "input_shape = (img_channels, img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 各ラベルごとに画像を10枚格納\n",
    "# img_list = []\n",
    "# for for_1 in range(3):\n",
    "#     choice_idx = np.random.choice(np.where(y_test == for_1)[0], 10)\n",
    "#     img_list.append(x_test[choice_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # データの可視化\n",
    "# for for_1 in range(3):\n",
    "#     fig, ax = plt.subplots(1, 10, figsize=(18, 8))\n",
    "#     for for_2 in range(10):\n",
    "#         ax[for_2].imshow(img_list[for_1][for_2].reshape(img_rows, img_cols, img_channels)) #for_2の値+nでn番目以降のテストデータを出力する．\n",
    "#         ax[for_2].set_title(type_labels[for_1])\n",
    "#         ax[for_2].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 正規化\n",
    "# x_train = x_train.astype(np.float32) / 255.\n",
    "# x_test = x_test.astype(np.float32) / 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import np_utils\n",
    "# # クラスベクトルをバイナリクラスの行列に変換する\n",
    "# y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "# y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # backendの違いによる次元数の入力型の調整(おまじない)\n",
    "# from keras import backend as K\n",
    "\n",
    "# if K.image_data_format() == 'channels_first':\n",
    "#     x_train = x_train.reshape(x_train.shape[0], img_channels, img_rows, img_cols)\n",
    "#     x_test = x_test.reshape(x_test.shape[0], img_channels, img_rows, img_cols)\n",
    "#     input_shape = (img_channels, img_rows, img_cols)\n",
    "# else:\n",
    "#     x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, img_channels)\n",
    "#     x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, img_channels)\n",
    "#     input_shape = (img_rows, img_cols, img_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout,Flatten,Conv2D,MaxPooling2D,BatchNormalization,Activation\n",
    "from keras import regularizers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# model.add()の中にConv2DやMaxPooling2Dをいれてモデルを作ってみよう\n",
    "\n",
    "# サンプルで使用している関数一覧\n",
    "# ---\n",
    "# # データの一次元配列化\n",
    "#     model.add(Flatten()) # 全結合層につなげる直前に使おう\n",
    "# # 全結合層\n",
    "#     model.add(Dense(次元数, activation=活性化関数)) \n",
    "# # 畳み込み層\n",
    "#     model.add(Conv2D(次元数, kernel_size=フィルターのサイズ,activation=活性化関数,input_shape=input_shape))\n",
    "# # プーリング層\n",
    "#     model.add(MaxPooling2D(pool_size=プーリングするサイズ))\n",
    "# # ドロップアウト\n",
    "# model.add(Dropout(0から1までの数値)) # 学習するパーセプトロンのうち使用しない割合を設定\n",
    "# ---\n",
    "\n",
    "# その他、調べてみて便利な関数があればぜひ追加してみよう\n",
    "# \"\"\"\n",
    "\n",
    "# weight_decay = 1e-4\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(32, (2,2), padding='same', activation='relu', input_shape=input_shape))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "# model.add(Conv2D(64, (2,2), padding='same', activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "# model.add(Conv2D(128, (2,2), padding='same', activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.4))\n",
    "\n",
    "# model.add(Conv2D(256, (2,2), padding='same', activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(0.4))\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dense(18, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.optimizers import SGD, Adadelta, Adam, RMSprop# 最適化手法\n",
    "# from keras import optimizers\n",
    "\n",
    "# \"\"\"\n",
    "# モデルを評価する関数をmodel.compile()で定義しよう\n",
    "\n",
    "# 実際にmodel.compileの中にはこのようにします\n",
    "\n",
    "# model.compile(loss=誤差関数,\n",
    "#              optimizer=最適化関数,\n",
    "#              metrics=['accuracy']\n",
    "#              )\n",
    "             \n",
    "# 誤差関数　モデルの精度の悪さを表す指標　誤差逆伝播時にパラメータの更新方向を決定する数値\n",
    "# ・categorical_crossentropy\n",
    "\n",
    "# 最適化関数(好きなものを選ぼう)　誤差逆伝播時にパラメータを更新する手法\n",
    "# ・SGD\n",
    "# ・Adadelta\n",
    "# ・Adam\n",
    "#   Adamは最近主流になっている最適化関数。一般的にSGDよりも優秀(例外はある)。\n",
    "# ・RMSprop\n",
    "\n",
    "# 評価指標\n",
    "# ・accuracy\n",
    "# \"\"\"\n",
    "# # 損失関数\n",
    "# # def categorical_loss(y_true, y_pred):\n",
    "# #     return K.categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "# # 評価関数\n",
    "# def total_acc(y_true, y_pred):\n",
    "#     pred = K.cast(K.greater_equal(y_pred, 0.5), \"float\")\n",
    "#     flag = K.cast(K.equal(y_true, pred), \"float\")\n",
    "#     return K.prod(flag, axis=-1)\n",
    "\n",
    "# def binary_acc(y_true, y_pred):\n",
    "#     pred = K.cast(K.greater_equal(y_pred, 0.5), \"float\")\n",
    "#     flag = K.cast(K.equal(y_true, pred), \"float\")\n",
    "#     return K.mean(flag, axis=-1)\n",
    "\n",
    "\n",
    "# model.compile(loss=\"categorical_crossentropy\", # 誤差(損失)関数\n",
    "#               optimizer=\"Adam\", # 最適化関数\n",
    "#               metrics=[total_acc, binary_acc] # 評価指標\n",
    "#              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \"\"\"\n",
    "    build a model.\n",
    "    \n",
    "    Returns :\n",
    "        model : \n",
    "            CNN model.\n",
    "    \"\"\"\n",
    "    \n",
    "    weight_decay = 1e-4\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (2,2), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(64, (2,2), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(128, (2,2), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (2,2), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(18, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 400 samples, validate on 401 samples\n",
      "Epoch 1/1\n",
      "400/400 [==============================] - 7s 17ms/step - loss: 5.6723 - total_acc: 0.0575 - binary_acc: 0.9193 - val_loss: 2.9878 - val_total_acc: 0.0000e+00 - val_binary_acc: 0.9444\n",
      "Test score: 2.987845058155773\n",
      "Test accuracy: 0.0\n",
      "-----------------------\n",
      "Train on 401 samples, validate on 400 samples\n",
      "Epoch 1/1\n",
      "401/401 [==============================] - 8s 20ms/step - loss: 5.5621 - total_acc: 0.0499 - binary_acc: 0.9127 - val_loss: 2.9799 - val_total_acc: 0.0000e+00 - val_binary_acc: 0.9444\n",
      "Test score: 2.9798889923095704\n",
      "Test accuracy: 0.0\n",
      "-----------------------\n",
      "test score average: 2.983867025232672\n",
      "test accuracy average: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "score_average = []\n",
    "accuracy_average = []\n",
    "\n",
    "# 損失関数\n",
    "def categorical_loss(y_true, y_pred):\n",
    "    return K.categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "# 評価関数\n",
    "def total_acc(y_true, y_pred):\n",
    "    pred = K.cast(K.greater_equal(y_pred, 0.5), \"float\")\n",
    "    flag = K.cast(K.equal(y_true, pred), \"float\")\n",
    "    return K.prod(flag, axis=-1)\n",
    "\n",
    "def binary_acc(y_true, y_pred):\n",
    "    pred = K.cast(K.greater_equal(y_pred, 0.5), \"float\")\n",
    "    flag = K.cast(K.equal(y_true, pred), \"float\")\n",
    "    return K.mean(flag, axis=-1)\n",
    "\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train = X_train.astype(np.float32) / 255.\n",
    "    X_test = X_test.astype(np.float32) / 255.\n",
    "    \n",
    "    Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "    Y_test = np_utils.to_categorical(Y_test, nb_classes)\n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        X_train = X_train.reshape(X_train.shape[0], img_channels, img_rows, img_cols)\n",
    "        X_test = X_test.reshape(xX_test.shape[0], img_channels, img_rows, img_cols)\n",
    "        input_shape = (img_channels, img_rows, img_cols)\n",
    "    else:\n",
    "        X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, img_channels)\n",
    "        X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, img_channels)\n",
    "        input_shape = (img_rows, img_cols, img_channels)\n",
    "    \n",
    "    model = get_model()\n",
    "    \n",
    "    model.compile(loss=categorical_loss, # 誤差(損失)関数\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4), # 最適化関数\n",
    "              metrics=[total_acc, binary_acc] # 評価指標\n",
    "             )\n",
    "    \n",
    "    history = model.fit(X_train, Y_train,\n",
    "                    batch_size=32,\n",
    "                    nb_epoch=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test)\n",
    "                   )\n",
    "    \n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test score:', score[0]) # 損失関数の値\n",
    "    score_average.append(score[0])\n",
    "    print('Test accuracy:', score[1]) # 精度\n",
    "    accuracy_average.append(score[1])\n",
    "    print('-----------------------')\n",
    "\n",
    "\n",
    "print(\"test score average:\", np.mean(score_average))\n",
    "print(\"test accuracy average:\", np.mean(accuracy_average))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/sequential.py:110: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
      "  warnings.warn('`Sequential.model` is deprecated. '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "#モデルの保存\n",
    "json_string = model.model.to_json()\n",
    "open('predict.json', 'w').write(json_string)\n",
    "\n",
    "#重みの保存\n",
    "hdf5_file = \"predict.hdf5\"\n",
    "model.model.save_weights(hdf5_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal\n"
     ]
    }
   ],
   "source": [
    "# from keras import models\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "def predict(image_pass):\n",
    "\n",
    "    #保存したモデルの読み込み\n",
    "    model = model_from_json(open('predict.json').read())\n",
    "    #保存した重みの読み込み\n",
    "    model.load_weights('predict.hdf5')\n",
    "\n",
    "\n",
    "    #画像を読み込む\n",
    "    img = Image.open(image_pass)\n",
    "    img = img.resize((64,64))\n",
    "    img = img.convert('RGBA')\n",
    "    x = np.array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    #予測\n",
    "    features = model.predict(x)\n",
    "\n",
    "    return type_labels[np.argmax(features)]\n",
    "\n",
    "img_pass = \"/workspace/data/images/0801.png\"\n",
    "print(predict(img_pass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook MultiClassClassification.ipynb to python\n",
      "[NbConvertApp] Writing 9793 bytes to MultiClassClassification.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python MultiClassClassification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
